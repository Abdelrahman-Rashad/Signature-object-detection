{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdelrahman-Rashad/Signature-object-detection/blob/main/realVSfake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D7YpXaIhOyj"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PG14YPc1hOyl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "from sklearn import svm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0z_zQQyhOyn"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B1j2ZHBhOyn"
      },
      "outputs": [],
      "source": [
        "def toNumpy(x_train, y_train, x_test, y_test):\n",
        "    for i in x_train.keys():\n",
        "        x_train[i] = np.array(x_train[i])\n",
        "        y_train[i] = np.array(y_train[i])\n",
        "    for i in x_test.keys():\n",
        "        x_test[i] = np.array(x_test[i])\n",
        "        y_test[i] = np.array(y_test[i])\n",
        "    return x_train, y_train, x_test, y_test\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfSnmvZAhOyo"
      },
      "outputs": [],
      "source": [
        "def loadData(folders_name:list):\n",
        "    x_train = {}\n",
        "    y_train = {}\n",
        "    x_test =  {}\n",
        "    y_test =  {}\n",
        "    \n",
        "    for name in folders_name:        \n",
        "        path = f\"data/{name}/Train/\" \n",
        "        data = pd.read_csv(path+f\"{name}_SigVerificationTrainLabels.csv\") \n",
        "        data  = data.loc[:,[\"image_name\",\"label\"]].astype(str)\n",
        "        data = data.reset_index() \n",
        "        # li =labels.loc[:,[\"label\"]].astype(str)\n",
        "        x_train[name] = []\n",
        "        y_train[name] = []\n",
        "        x_test[name] =  []\n",
        "        y_test[name] =  []\n",
        "\n",
        "        # print(data.head())\n",
        "        for i,r in data.iterrows():\n",
        "\n",
        "            imgName = str(r[\"image_name\"])\n",
        "            img=cv2.imread(path+imgName, 0)\n",
        "            # img = img.astype(np.float32)    \n",
        "            x_train[name].append(img)\n",
        "            \n",
        "            l =  str(r[\"label\"])\n",
        "            y_train[name].append(1) if l == \"real\" else y_train[name].append(0) \n",
        "            \n",
        "        \"#====================================================================================\" \n",
        "        \n",
        "        path = f\"data/{name}/Test/\" \n",
        "        data = pd.read_csv(path+f\"{name}_SigVerificationTestLabels.csv\")\n",
        "        data = data.reset_index()  \n",
        "        data  = data.loc[:,[\"image_name\",\"label\"]].astype(str)\n",
        "        data = data.reset_index()\n",
        "        \n",
        "        for i,r in data.iterrows():\n",
        "            imgName = str(r[\"image_name\"])\n",
        "            img=cv2.imread(path+imgName, 0)\n",
        "            # img = img.astype(np.float32)       \n",
        "            x_test[name].append(img)\n",
        "            \n",
        "            l =  str(r[\"label\"])\n",
        "            y_test[name].append(1) if l == \"real\" else y_test[name].append(0) \n",
        "            \n",
        "            \n",
        "            \n",
        "    return toNumpy(x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpqaDl0HhOyo"
      },
      "source": [
        "#   **Extract Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeHHR3jahOyp"
      },
      "outputs": [],
      "source": [
        "def normalization(features:np.ndarray, o):\n",
        "    if o == 1:\n",
        "        m = features.mean(axis=1)\n",
        "        s = features.std(axis=1) \n",
        "        features = (features.T-m)/(s+1e-7)\n",
        "        return features.T.flatten()\n",
        "    if features.ndim > 1:\n",
        "        features = features.flatten()\n",
        "    m = features.mean()\n",
        "    s = features.std()\n",
        "    return (features-m)/(s+1e-7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRutJnMQhOyp"
      },
      "outputs": [],
      "source": [
        "def featureExtractionM(img,o=1):\n",
        "   \n",
        "    if o == 0: \n",
        "        hog = cv2.HOGDescriptor()\n",
        "        img= cv2.resize(img, (64,128))\n",
        "        features = hog.compute(img)\n",
        "        features = normalization(features, o)\n",
        "\n",
        "    elif o == 1:\n",
        "        sift = cv2.SIFT_create()\n",
        "        img= cv2.resize(img, (128,128))\n",
        "        kp1, features = sift.detectAndCompute(img,None)\n",
        "        if features.shape[0]<=64:\n",
        "            features = np.concatenate([features,np.zeros((64-features.shape[0],128))], axis = 0)\n",
        "        else:\n",
        "            features = features[0:64,:]\n",
        "        features = normalization(features, o)\n",
        "\n",
        "    elif o == 2:\n",
        "        img= cv2.resize(img, (64,32))\n",
        "        features = cv2.Canny(img, 32, 128)\n",
        "        features = normalization(features, o)\n",
        "        \n",
        "    elif o == 3:\n",
        "        img= cv2.resize(img, (128,64))\n",
        "        dst = cv2.GaussianBlur(img,(3,3),cv2.BORDER_DEFAULT,sigmaX=0.1,sigmaY=0.1)\n",
        "        featuresX = cv2.Sobel(src=dst, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axis\n",
        "        featuresY = cv2.Sobel(src=dst, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axis\n",
        "        features =np.arctan(featuresY/(featuresX+1e-7))\n",
        "        # sobelxy = cv2.Sobel(src=dst, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection\n",
        "        features = normalization(features, o)        \n",
        "        \n",
        "    elif o == 4:\n",
        "        img= cv2.resize(img, (128,64))\n",
        "        dst = cv2.GaussianBlur(img,(3,3),cv2.BORDER_DEFAULT,sigmaX=0.1,sigmaY=0.1)\n",
        "        featuresX = cv2.Sobel(src=dst, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axis\n",
        "        featuresY = cv2.Sobel(src=dst, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axis\n",
        "        features = featuresY + featuresX\n",
        "        features = normalization(features, o) \n",
        "        \n",
        "    elif 0 == 5:\n",
        "        img = np.float32(img)\n",
        "        features = cv2.cornerHarris(img,2,3,0.04)\n",
        "        #result is dilated for marking the corners, not important\n",
        "        features = cv2.dilate(dst,None) \n",
        "        features = normalization(features, o)      \n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT77borrhOyq"
      },
      "outputs": [],
      "source": [
        "def extract(x_train,x_test, o=0):\n",
        "    for name in x_train.keys():\n",
        "        x_featuresTrain = []\n",
        "        for i in x_train[name]:\n",
        "            f = featureExtractionM(i,o)\n",
        "            x_featuresTrain.append(f)\n",
        "        x_train[name] = np.array(x_featuresTrain)\n",
        "        \n",
        "        x_featuresTest = []   \n",
        "        for i in x_test[name]:\n",
        "            f = featureExtractionM(i,o)\n",
        "            x_featuresTest.append(f)\n",
        "        x_test[name] = np.array(x_featuresTest)\n",
        "    return x_train,x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQjgJnoyhOyr"
      },
      "source": [
        "#   **Svm Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxOTJLqlhOyr"
      },
      "outputs": [],
      "source": [
        "def buildSvm(x_train, y_train):\n",
        "    Svms = {}\n",
        "    for name in x_train.keys():\n",
        "        Svms[name] = svm.SVC(C=10,kernel=\"rbf\",gamma=\"auto\", )\n",
        "        Svms[name].fit(x_train[name], y_train[name])\n",
        "    return Svms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Flze3rshOyr"
      },
      "outputs": [],
      "source": [
        "def score(Svms, x, y):\n",
        "    scores={}\n",
        "    for name in x.keys():\n",
        "       scores[name] = Svms[name].score(x[name] , y[name])\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VVoBgybhOyr"
      },
      "source": [
        "#   **Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGxjuvHQhOys"
      },
      "outputs": [],
      "source": [
        "folders_name=[\"personA\",\"personB\",\"personC\",\"personD\",\"personE\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zoAjiZGhOys",
        "outputId": "b6306321-e6a9-4cb4-ede6-28ec409ec4c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_16296\\3107238934.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_train[i] = np.array(x_train[i])\n",
            "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_16296\\3107238934.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_test[i] = np.array(x_test[i])\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train, x_test, y_test = loadData(folders_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGSJNxXNhOyt"
      },
      "outputs": [],
      "source": [
        "x_train,x_test = extract(x_train,x_test, o=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5jAb-bGhOyt"
      },
      "outputs": [],
      "source": [
        "Svms = buildSvm(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnmZAiMMhOyt"
      },
      "outputs": [],
      "source": [
        "strain = score(Svms, x_train, y_train)\n",
        "stest = score(Svms, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U21vOBShOyt",
        "outputId": "4840e7f5-21fb-46ac-a5a6-f52d80382945"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'personA': 1.0,\n",
              "  'personB': 1.0,\n",
              "  'personC': 1.0,\n",
              "  'personD': 1.0,\n",
              "  'personE': 1.0},\n",
              " '=================\\n',\n",
              " {'personA': 0.875,\n",
              "  'personB': 0.625,\n",
              "  'personC': 1.0,\n",
              "  'personD': 0.875,\n",
              "  'personE': 1.0})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "strain,'=================\\n', stest"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "69f2af9667b3aee16a0e64ccfd54dc35db6d29042fedc7b9ffa5a98b188aebec"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}